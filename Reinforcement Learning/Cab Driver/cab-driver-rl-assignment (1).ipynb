{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0af609e1-23c4-4811-afbc-399196ca22c1",
    "_uuid": "8b2af43c-2f26-4ad4-8ff1-bf1424e6f53c"
   },
   "source": [
    "### Cab-Driver Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "430db985-a8ef-46db-adc0-115ee495c14c",
    "_uuid": "65f04bd4-f3bf-4b32-9a7f-a33e3ab3c227",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import deque\n",
    "import collections\n",
    "import pickle\n",
    "\n",
    "# for building DQN model\n",
    "from keras import layers\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# for plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Import the environment\n",
    "from Env import CabDriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "31da836f-c8a6-4f2d-a046-856463dffb8d",
    "_uuid": "43ef0864-3825-4a33-808d-70345c0bda08"
   },
   "source": [
    "#### Defining Time Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "c5f0eecb-d84f-4fea-adfc-57486f2fa71c",
    "_uuid": "4e05ca6a-d7c9-48bb-b3f3-f09aa6c4a7a9",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Loading the time matrix provided\n",
    "Time_matrix = np.load(\"TM.npy\")\n",
    "#Time_matrix = np.load(\"../input/time-matrix/TM.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bfccc48e-37bf-4dba-857a-b4fd2c5fe85c",
    "_uuid": "0f1e12b3-7abe-4748-8dce-aca48571214a"
   },
   "source": [
    "#### Tracking the state-action pairs for checking convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "7e16145c-0b41-408f-bb14-1524303d8558",
    "_uuid": "af3121ce-4fe9-4b71-acc7-a541b9ac43fd",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Q_dict = collections.defaultdict(dict)\n",
    "# States_track = collections.defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To initialise the track states\n",
    "# def initialise_tracking_states():\n",
    "#     # Tracking the state action pair ((2,2,0), (0,0)). \n",
    "#     # Since the action (0,0) is at position 0, we will denote action index 0 to point to 0 action\n",
    "#     sample_q_values = [(\"0_1_0_0_0_0_0_1_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_0_1_0_0_0_0_0_0\", 0)]\n",
    "#     for q_value in sample_q_values:\n",
    "#         state = q_value[0]\n",
    "#         action = q_value[1]\n",
    "#         States_track[state][action] = []\n",
    "\n",
    "# # # Saving the q values of the track states\n",
    "# def save_tracking_states():\n",
    "#     for state in States_track.keys():\n",
    "#         for action_index in States_track[state].keys():\n",
    "#             q_value = agent.model.predict(np.array(state.split(\"_\")).reshape(1,36))\n",
    "#             States_track[state][action].append(q_value[0][action_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b8105f25-0afc-4df1-af0a-7b94a3b7f925",
    "_uuid": "0e191b15-cf0c-4150-810a-ddee9faeb68f",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Saving the rewards per episode in the pickle file\n",
    "\n",
    "def save_pickle(obj, name):\n",
    "    write_start_time = time.time()\n",
    "    with open(name + \".pkl\", \"wb\") as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "    write_time_taken = time.time()-write_start_time\n",
    "    print(\"Writing the pickle file completed in \" + str(write_time_taken/60) + \" minutes\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "07546f78-752d-44b8-9b32-e7f5fdd3eaba",
    "_uuid": "eb07d54d-97f0-4349-98af-af36530201ed"
   },
   "source": [
    "### Agent Class\n",
    "\n",
    "If you are using this framework, you need to fill the following to complete the following code block:\n",
    "1. State and Action Size\n",
    "2. Hyperparameters\n",
    "3. Create a neural-network model in function 'build_model()'\n",
    "4. Define epsilon-greedy strategy in function 'get_action()'\n",
    "5. Complete the function 'append_sample()'. This function appends the recent experience tuple <state, action, reward, new-state> to the memory\n",
    "6. Complete the 'train_model()' function with following logic:\n",
    "   - If the memory size is greater than mini-batch size, you randomly sample experiences from memory as per the mini-batch size and do the following:\n",
    "      - Initialise your input and output batch for training the model\n",
    "      - Calculate the target Q value for each sample: reward + gamma*max(Q(s'a,))\n",
    "      - Get Q(s', a) values from the last trained model\n",
    "      - Update the input batch as your encoded state and output batch as your Q-values\n",
    "      - Then fit your DQN model using the updated input and output batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "a8f3d234-9287-4863-a758-dd6329d40f2f",
    "_uuid": "5a62105e-c977-47c4-ac2e-6a17eb6dded2",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # Define size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # Write here: Specify you hyper parameters for the DQN\n",
    "        self.discount_factor = 0.95\n",
    "        self.learning_rate = 0.01     \n",
    "        self.epsilon_max = 1.0\n",
    "        self.epsilon_decay = -0.0005\n",
    "        self.epsilon_min = 0.00001\n",
    "        self.epsilon = 1.0\n",
    "\n",
    "        self.batch_size = 32        \n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        \n",
    "        self.state_to_track = (2,2,0)\n",
    "        self.action_index_to_track = 0\n",
    "        self.state_tracking = []\n",
    "\n",
    "        # create main model and target model\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        # Write your code here: Add layers to your neural nets       \n",
    "        model.add(Dense(32, input_dim=self.state_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "        \n",
    "        # the output layer: output is of size num_actions\n",
    "        model.add(Dense(self.action_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.compile(loss='mse',optimizer=Adam(lr=self.learning_rate))\n",
    "        model.summary\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "    def get_action(self, state, episode):\n",
    "    # Write your code here:\n",
    "    # get action from model using epsilon-greedy policy\n",
    "    # Decay in Îµ after we generate each sample from the environment       \n",
    "#         epsilon = self.epsilon_min + (self.epsilon_max - self.epsilon_min) * np.exp(-0.000001*episode)\n",
    "        z = np.random.random()\n",
    "        \n",
    "        possible_actions_index, agent_allowable_actions = list(env.requests(state))        \n",
    "        if z > self.epsilon:\n",
    "            # Exploitation\n",
    "            encoded_state =np.array(env.state_encod_arch1(state)).reshape(1,36)\n",
    "            q_value = self.model.predict(encoded_state)    \n",
    "            allowed_q_values = [q_value[0][i] for i in possible_actions_index]\n",
    "            action_index = possible_actions_index[np.argmax(allowed_q_values)]\n",
    "        else:\n",
    "            # Exploration\n",
    "            action_index = random.choice(possible_actions_index)            \n",
    "        return action_index\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def append_sample(self, state, action_index, reward, next_state, terminal_state):\n",
    "    # Write your code here:\n",
    "    # save sample <s,a,r,s'> to the replay memory\n",
    "        self.memory.append((state, action_index, reward, next_state, terminal_state))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # pick samples randomly from replay memory (with batch_size) and train the network\n",
    "    def train_model(self):\n",
    "        \n",
    "        if len(self.memory) > self.batch_size:\n",
    "            # Sample batch from the memory\n",
    "            mini_batch = random.sample(self.memory, self.batch_size)\n",
    "            update_output = np.zeros((self.batch_size, self.state_size))\n",
    "            update_input = np.zeros((self.batch_size, self.state_size))\n",
    "            \n",
    "            actions, rewards, done = [], [], []\n",
    "            \n",
    "            for i in range(self.batch_size):\n",
    "                state, action, reward, next_state, terminal_state = mini_batch[i]\n",
    "                \n",
    "                actions.append(action_index)\n",
    "                rewards.append(reward)\n",
    "                done.append(terminal_state)\n",
    "                \n",
    "                update_input[i] = env.state_encod_arch1(state)\n",
    "                update_output[i] = env.state_encod_arch1(next_state)\n",
    "                \n",
    "            # Write your code from here\n",
    "            # 1. Predict the target from earlier model\n",
    "            target = self.model.predict(update_input)   \n",
    "\n",
    "            # 2. Get the target for the Q-network\n",
    "            target_qval = self.model.predict(update_output)\n",
    "\n",
    "            #3. Update your 'update_output' and 'update_input' batch\n",
    "            for i in range(self.batch_size):\n",
    "                if done[i]:\n",
    "                    target[i][actions[i]] = rewards[i]\n",
    "                else: # non-terminal state\n",
    "                    target[i][actions[i]] = rewards[i] + self.discount_factor * np.max(target_qval[i])  \n",
    "                \n",
    "                \n",
    "            # 4. Fit your model and track the loss values\n",
    "            self.model.fit(update_input, target, batch_size=self.batch_size, epochs=1, verbose=0)\n",
    "\n",
    "\n",
    "    def save(self, name):\n",
    "        save_start_time = time.time()\n",
    "        self.model.save(name)\n",
    "        save_time_taken = time.time() - save_start_time\n",
    "        print(\"Saving the model completed in \" + str(save_time_taken/60) + \" minu\")\n",
    "\n",
    "    # # Saving the q values of the track states\n",
    "    def save_tracking_states(self):\n",
    "        q_value = agent.model.predict(np.array(env.state_encod_arch1(self.state_to_track)).reshape(1,36))\n",
    "        self.state_tracking.append(q_value[0][self.action_index_to_track])                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "f01cd0cf-aa9f-4499-b55f-603506c6830a",
    "_uuid": "f328c6c3-2970-4436-af71-59e4c4812ebb",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "Episodes = 15000\n",
    "write_threshold = 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a0c6fe4d-9d18-4454-aa76-e4b1e2c1ca7a",
    "_uuid": "20ef9e64-29ff-4645-b8dc-762271f90e0f"
   },
   "source": [
    "### DQN block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "63882afa-87d8-4677-aa06-2503d86d0ec9",
    "_uuid": "0377131a-bc92-4e67-a955-5a857511ec88",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0, reward -146.0, memory_length 128, epsilon 1.0\n",
      "Saving the model completed in 0.00018334786097208658 minu\n",
      "Writing the pickle file completed in 0.0 minutes\n",
      "episode 500, reward -73.0, memory_length 2000, epsilon 0.7788029950635742\n",
      "episode 1000, reward 111.0, memory_length 2000, epsilon 0.6065345944060363\n",
      "episode 1500, reward -65.0, memory_length 2000, epsilon 0.4723718290754873\n",
      "episode 2000, reward 207.0, memory_length 2000, epsilon 0.36788576237703063\n",
      "episode 2500, reward -145.0, memory_length 2000, epsilon 0.2865119318122215\n",
      "episode 3000, reward -30.0, memory_length 2000, epsilon 0.22313792884682834\n",
      "Saving the model completed in 0.00023323297500610352 minu\n",
      "Writing the pickle file completed in 9.919404983520508e-05 minutes\n",
      "episode 3500, reward -237.0, memory_length 2000, epsilon 0.17378220571101066\n",
      "episode 4000, reward -202.0, memory_length 2000, epsilon 0.13534392988378036\n",
      "episode 4500, reward 262.0, memory_length 2000, epsilon 0.10540817056961871\n",
      "episode 5000, reward -338.0, memory_length 2000, epsilon 0.08209417777391256\n",
      "episode 5500, reward 57.0, memory_length 2000, epsilon 0.0639372219280955\n",
      "episode 6000, reward 187.0, memory_length 2000, epsilon 0.049796570497180274\n",
      "Saving the model completed in 0.005299921830495199 minu\n",
      "Writing the pickle file completed in 0.0004724423090616862 minutes\n",
      "episode 6500, reward -310.0, memory_length 2000, epsilon 0.0387838200896437\n",
      "episode 7000, reward -17.0, memory_length 2000, epsilon 0.030207081448484278\n",
      "episode 7500, reward 243.0, memory_length 2000, epsilon 0.023527510678550547\n",
      "episode 8000, reward -316.0, memory_length 2000, epsilon 0.018325455732345293\n",
      "episode 8500, reward -325.0, memory_length 2000, epsilon 0.014274091266660165\n",
      "episode 9000, reward -473.0, memory_length 2000, epsilon 0.011118885448276924\n",
      "Saving the model completed in 0.006983359654744466 minu\n",
      "Writing the pickle file completed in 0.0007850845654805501 minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "state_size = 36\n",
    "action_size = 21\n",
    "\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "rewards_per_episode, episodes = [], []\n",
    "\n",
    "for episode in range(Episodes):\n",
    "\n",
    "    score = 0\n",
    "    # Write code here\n",
    "    # Call the environment\n",
    "    env = CabDriver()\n",
    "    # Call all the initialised variables of the environment\n",
    "    (action_space, state_space, state) = env.reset()\n",
    "    terminal_state = False\n",
    "\n",
    "    #Call the DQN agent\n",
    "    \n",
    "    count = 0\n",
    "    while not terminal_state:\n",
    "        \n",
    "        # Write your code here\n",
    "        count+=1\n",
    "        # 1. Pick epsilon-greedy action from possible actions for the current state\n",
    "        action_index = agent.get_action(state, episode)\n",
    "        action = action_space[action_index]\n",
    "        # 2. Evaluate your reward and next state\n",
    "        reward = env.reward_func(state, action, Time_matrix)\n",
    "        next_state, terminal_state = env.next_state_func(state, action, Time_matrix) \n",
    "        # 3. Append the experience to the memory\n",
    "        agent.append_sample(state, action_index, reward, next_state, terminal_state)\n",
    "        # 4. Train the model by calling function agent.train_model\n",
    "        if (episode%100 ==0):\n",
    "            agent.train_model()\n",
    "        # 5. Keep a track of rewards, Q-values, loss\n",
    "        score += reward\n",
    "        state = next_state\n",
    "    \n",
    "    # Store total rewards obtained in this episode\n",
    "    rewards_per_episode.append(score)\n",
    "    episodes.append(episode)\n",
    "    \n",
    "    # epsilon decay\n",
    "    if agent.epsilon > agent.epsilon_min:\n",
    "#         agent.epsilon *= agent.epsilon_decay\n",
    "        agent.epsilon = agent.epsilon_min + (agent.epsilon_max - agent.epsilon_min) * np.exp(agent.epsilon_decay*episode)\n",
    "    \n",
    "    # Logging every episode\n",
    "#     print(\"episode {0}, reward {1}, memory_length {2}, epsilon {3}\".format(episode, score, len(agent.memory), agent.epsilon))\n",
    "    \n",
    "    # Initialising the State_track dictionary to track the state\n",
    "#     if (episode == track_threshold-1):\n",
    "#         initialise_tracking_states()\n",
    "\n",
    "    if (episode%500 ==0):\n",
    "        print(\"episode {0}, reward {1}, memory_length {2}, epsilon {3}\".format(episode, score, len(agent.memory), agent.epsilon))        \n",
    "    \n",
    "    if (episode%10 ==0):\n",
    "        agent.save_tracking_states()\n",
    "\n",
    "    # Every few episodes\n",
    "    if episode%write_threshold == 0:\n",
    "        # Saving the models\n",
    "        agent.save(\"model_weights.h5\")\n",
    "        # Saving the rewards per episode as a pickle file\n",
    "        save_pickle(rewards_per_episode,\"rewards_per_episode\")\n",
    "\n",
    "##### Simulation ends ######\n",
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time/3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "57796a49-f5fa-41dc-9394-ae7a22eb3ef7",
    "_uuid": "609d36a4-f07d-4eb9-b986-3764adbad99f"
   },
   "source": [
    "### Tracking Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "eb11f917-1b54-42b4-93fc-eaa0b684987b",
    "_uuid": "4ad8c490-1008-410f-8561-3c2d14ddd6a1",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"rewards_per_episode.pkl\", \"rb\") as f:\n",
    "    rewards_per_episode = pickle.load(f)\n",
    "\n",
    "plt.plot(list(range(len(rewards_per_episode))), rewards_per_episode)\n",
    "plt.xlabel(\"episode number\")\n",
    "plt.ylabel(\"rewards per episode\")\n",
    "plt.savefig('rewards.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.remove(\"./model_weights.h5\")\n",
    "# os.remove(\"./rewards_per_episode.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3dd2aa28-35ec-470b-a1be-ce6e4e3b7551",
    "_uuid": "b6301198-c23a-425c-9715-8bc2557b6a35"
   },
   "source": [
    "#### Epsilon-decay sample function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "04efc647-9226-41ee-ab2d-b4ac4ee5e569",
    "_uuid": "bba09de4-e91e-4f13-add9-9bb89d260490"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Try building a similar epsilon-decay function for your model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.epsilon_max = 1.0\n",
    "        self.epsilon_decay = -0.0005\n",
    "        self.epsilon_min = 0.00001\n",
    "        self.epsilon = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f1274125-5c80-4720-84aa-015b6d4f1c40",
    "_uuid": "8244329d-3737-46d9-a226-823abd83f7ac",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "time = np.arange(0,15000)\n",
    "epsilon = []\n",
    "for i in range(0,15000):\n",
    "    epsilon.append(0.00001 + (1 - 0.00001) * np.exp(-0.0005*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f8389caa-942c-4f35-a4e7-0bae53f53787",
    "_uuid": "7da80223-bf90-4a30-91da-5a312de5d932",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(time, epsilon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "69407602-ca5f-4671-9ec3-5123e9d22125",
    "_uuid": "92a7fa52-93f3-4793-870a-06d2967ec631",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
